{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Tweet Processing\n",
    "Iterate tweets for a given day and perform some calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# required imports to access api_db, misc, misc.CONFIG, ...\n",
    "import sys\n",
    "sys.path = ['.', '..', '../..'] + sys.path\n",
    "from collection import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 align=\"center\">driver code</h1>\n",
    "\n",
    "1. Define tasks to execute daily\n",
    "2. Check if these have been executed for each day of the past month\n",
    "3. Execute the ones that have not yet been executed (this ensures that new ones will be retroactively updated)\n",
    "4. "
   ]
  },
  {
   "source": [
    "---\n",
    "Define tasks below - these should be replicated in the api (or maybe make it generably able to access any `task_%s` collection from any endpoint, assuming injection is not a concern atm)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1 - count tweets by type\n",
    "from collections import defaultdict\n",
    "def count_tweets_by_type(day, recalculate=False):\n",
    "    task = Task(api_db.db, \"count by type\")\n",
    "    if task.exists_day(day) and not recalculate: return # already processed\n",
    "    metrics = defaultdict(int, next(api_db.col_tweets.aggregate([\n",
    "        {\"$match\": {\"created_at\": get_filter_by_day(day)}}, \n",
    "        {\"$facet\": {\n",
    "            \"retweet\": [\n",
    "                {\"$match\": {\"retweeted_status\": {\"$exists\": True}}},\n",
    "                {\"$count\": \"retweet\"},\n",
    "            ],\n",
    "            \"quote\": [\n",
    "                {\"$match\": {\"quoted_status\": {\"$exists\": True}}},\n",
    "                {\"$count\": \"quote\"},\n",
    "            ],\n",
    "            \"reply\": [\n",
    "                {\"$match\": {\"in_reply_to_status_id\": {\"$exists\": True}}},\n",
    "                {\"$count\": \"reply\"},\n",
    "            ],\n",
    "            \"original\": [\n",
    "                {\"$match\": {\"original\": True}},\n",
    "                {\"$count\": \"original\"},\n",
    "            ],\n",
    "            \"total\": [\n",
    "                {\"$count\": \"total\"},\n",
    "            ]\n",
    "        }},\n",
    "        {\"$project\": {\n",
    "            \"retweet\": {\"$arrayElemAt\": [\"$retweet.retweet\", 0]},\n",
    "            \"quote\": {\"$arrayElemAt\": [\"$quote.quote\", 0]},\n",
    "            \"reply\": {\"$arrayElemAt\": [\"$reply.reply\", 0]},\n",
    "            \"original\": {\"$arrayElemAt\": [\"$original.original\", 0]},\n",
    "            \"total\": {\"$arrayElemAt\": [\"$total.total\", 0]}\n",
    "        }}\n",
    "    ])))\n",
    "    # force defaultdict to create 0\n",
    "    [metrics[x] for x in [\"retweet\", \"quote\", \"reply\", \"original\", \"total\"]]\n",
    "    task.insert(day, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2 - measure fake news\n",
    "def measure_fakenews(day, recalculate=False):\n",
    "    task = Task(api_db.db, \"measure fakenews\")\n",
    "    if task.exists_day(day) and not recalculate: return # already processed\n",
    "\n",
    "    # helper function\n",
    "    from urllib.parse import urlparse\n",
    "    def netloc(url): return urlparse(url.strip()).netloc.replace(\"www.\", \"\")\n",
    "\n",
    "    def normalize_name(name): return name.replace(\".\", \"-\")\n",
    "\n",
    "    # get fakenews sites\n",
    "    with open(abs_path(\"../resources/fakenews.txt\")) as inf: fakenews_sites = set(map(lambda s: s.strip(), inf.readlines()))\n",
    "    # search query\n",
    "    tweets = api_db.col_tweets.find({\n",
    "        \"urls\":{\"$exists\": True},\n",
    "        \"created_at\": get_filter_by_day(day)\n",
    "        }, {\"urls\": True, \"user\": True, \"favorite_count\": True, \"retweet_count\": True})\n",
    "    # collect\n",
    "    metrics = {\"total\":0, \"sites\": {}, \"favorite_count\": 0, \"retweet_count\": 0}\n",
    "    for fake in fakenews_sites: metrics[\"sites\"][normalize_name(fake)]=0\n",
    "    for t in tweets:\n",
    "        for url in t[\"urls\"]:\n",
    "            loc = netloc(url[\"expanded_url\"])\n",
    "            if loc == \"facebook.com\":\n",
    "                for fake in fakenews_sites:\n",
    "                    if fake in url[\"expanded_url\"]:\n",
    "                        metrics[\"sites\"][normalize_name(fake)]+=1\n",
    "                        if \"favorite_count\" in t: metrics[\"favorite_count\"]+=t[\"favorite_count\"]\n",
    "                        if \"retweet_count\" in t: metrics[\"retweet_count\"]+=t[\"retweet_count\"]\n",
    "                        break\n",
    "            elif loc in fakenews_sites:\n",
    "                metrics[\"sites\"][normalize_name(loc)]+=1\n",
    "                if \"favorite_count\" in t: metrics[\"favorite_count\"]+=t[\"favorite_count\"]\n",
    "                if \"retweet_count\" in t: metrics[\"retweet_count\"]+=t[\"retweet_count\"]\n",
    "    metrics[\"total\"] = sum(v for k, v in metrics[\"sites\"].items())\n",
    "    task.insert(day, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3 - measure suspensions\n",
    "def measure_suspensions(day, recalculate=False):\n",
    "    task = Task(api_db.db, \"measure suspensions\")\n",
    "    # force recalculation each day\n",
    "    # if task.exists_day(day) and not recalculate: return # already processed\n",
    "\n",
    "    metrics = {\"total\":0, \"users\": []}\n",
    "    users = api_db.col_users.find({\"suspended\": True, \"time_suspended\": get_filter_by_day(day)},\n",
    "     {\"screen_name\": True, \"friends_count\": True, \"followers_count\": True, \"statuses_count\": True, \"description\": True, \"favourites_count\": True, \"created_at\": True})\n",
    "    \n",
    "    for user in users:\n",
    "        metrics[\"total\"]+=1\n",
    "        metrics[\"users\"].append(user)\n",
    "\n",
    "    task.insert(day, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates\n",
    "# candidates = [(\"AnaMartinsGomes\", 771383605), (\"AndreCVentura\", 1097962618596327424), (\"BrunoARFialho\", 1221188948996739072), (\"joao_ferreira33\", 951055588330475520), (\"mmatias_\", 948552829), (\"Marcelo Rebelo de Sousa\", 0), (\"LiberalMayan\", 1286335166881964032), (\"_tinoderans_\", 4644839074)]\n",
    "candidates = [(\"MarceloRebeloDeSousa\", 0), (\"AnaMartinsGomes\", 771383605), (\"AndreCVentura\", 1097962618596327424), (\"BrunoARFialho\", 1221188948996739072), (\"joao_ferreira33\", 951055588330475520), (\"mmatias_\", 948552829), (\"LiberalMayan\", 1286335166881964032), (\"_tinoderans_\", 4644839074)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsterms = HatespeechTerms('../resources/hatespeech_terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# measures hatespeech terms and insults in replies to candidates content\n",
    "# aggregations are done on frontend side\n",
    "def measure_hatespeech(day, recalculate=False):\n",
    "    task = Task(api_db.db, \"measure hatespeech\")\n",
    "    if task.exists_day(day) and not recalculate: return # already processed\n",
    "\n",
    "    metrics = {\"candidates\": {}} # daily metrics\n",
    "    # enrich metrics with each candidate's daily replies\n",
    "    for user, _id in candidates:\n",
    "        if _id <= 0: continue # ignore marcelo\n",
    "        _id_str = str(_id)\n",
    "        replies_to_candidate = api_db.col_tweets.find({\"in_reply_to_user_id\": _id, \"created_at\": get_filter_between_days(day, day)}, {\"full_text\": True})\n",
    "        \n",
    "        candidate_matches = []\n",
    "        total_replies = 0\n",
    "        for t in replies_to_candidate:\n",
    "            total_replies+=1\n",
    "            candidate_matches.extend(hsterms.find_all_words(t[\"full_text\"]))\n",
    "        \n",
    "        metrics[\"candidates\"][_id_str] = {\"total_replies\": total_replies, \"hits\": candidate_matches}\n",
    "    \n",
    "    task.insert(day, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def refresh_candidates_tweets():\n",
    "    oldest_t = misc.CONFIG[\"collection\"][\"oldest_tweet\"]\n",
    "    for username, _id in candidates:\n",
    "        if _id <= 0: continue # ignore marcelo\n",
    "        with DoneMessage(\"Refreshing %s\" % username):\n",
    "            # refresh all tweets to get updated values for likes, ... since oldest_t\n",
    "            tweets = get_tweets({\"_id\": _id}, api_db.api.GetUserTimeline, \"since_id\", oldest_t, {\"trim_user\":True})\n",
    "            insert_tweets(tweets)\n",
    "            print(\"refreshed %d tweets\" % len(tweets), end=\"\")\n",
    "refresh_candidates_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# task 4 - measure presidential candidates\n",
    "import re\n",
    "def measure_candidates(day, recalculate=False):\n",
    "    task = Task(api_db.db, \"measure candidates\")\n",
    "    if task.exists_day(day) and not recalculate: return # already processed\n",
    "\n",
    "\n",
    "    metrics = {\"candidates\": {}} # daily metrics\n",
    "    # global_metrics = {} # only one doc in the collection, which is updated\n",
    "    def get_tweet_type(tweet):\n",
    "        if \"original\" in tweet: return \"original\"\n",
    "        if \"retweeted_status\" in tweet: return \"retweet\"\n",
    "        if \"quoted_status\" in tweet: return \"quote\"\n",
    "        if \"in_reply_to_user_id\" in tweet or \"in_reply_to_status_id\" in tweet: return \"reply\"\n",
    "        return \"original\"\n",
    "\n",
    "    for user, _id in candidates:\n",
    "        _id_str = str(_id)\n",
    "        # account metrics for this day\n",
    "        account = get_account_details(user_id=_id)\n",
    "        if account:\n",
    "            account = user_to_db_format(account)\n",
    "            upsert_user(account)\n",
    "        else: account = api_db.col_users.find_one({\"_id\": _id})\n",
    "        metrics[\"candidates\"][_id_str] = {\n",
    "            \"name\": account[\"name\"],\n",
    "            \"screen_name\": account[\"screen_name\"],\n",
    "            \"followers_count\": account[\"followers_count\"],\n",
    "            \"tweets\": []\n",
    "        }\n",
    "        if \"profile_image_url_https\" in account: # adds profile picture\n",
    "            metrics[\"candidates\"][_id_str][\"pic\"] = account[\"profile_image_url_https\"]\n",
    "        # tweet metrics for this day\n",
    "        tweets = api_db.col_tweets.find({\"user\": _id, \"created_at\": get_filter_by_day(day)},\n",
    "                {\"retweet_count\": True, \"favorite_count\": True, \"retweeted_status\": True, \"quoted_status\": True, \"in_reply_to_status_id\": True, \"in_reply_to_user_id\": True, \"original\": True, \"full_text\": True, \"created_at\": True})\n",
    "        for t in tweets:\n",
    "            if \"retweet_count\" not in t: t[\"retweet_count\"] = 0\n",
    "            if \"favorite_count\" not in t: t[\"favorite_count\"] = 0\n",
    "            _tweet = {\"_id\": t[\"_id\"], \"retweet_count\": t[\"retweet_count\"], \"favorite_count\": t[\"favorite_count\"], \"type\": get_tweet_type(t), \"created_at\": t[\"created_at\"], \"full_text\": t[\"full_text\"]}\n",
    "            # if \"original\" in t or \"quoted_status\" in t: _tweet[\"full_text\"] = t[\"full_text\"]\n",
    "            metrics[\"candidates\"][_id_str][\"tweets\"].append(_tweet)\n",
    "        # there was a bug with this metric so, since all the info is in the UI, it was fixed there because of historical data, however this query is now correct but will not be used for the current deployment, TODO: fix for later ones\n",
    "        metrics[\"candidates\"][_id_str][\"tweet_impact\"] = sum(t[\"retweet_count\"] + t[\"favorite_count\"] for t in metrics[\"candidates\"][_id_str][\"tweets\"] if t[\"type\"] != \"retweet\")\n",
    "\n",
    "        # count name mentions and mentions\n",
    "        candidate_name = ''.join([i for i in account[\"name\"] if not i.isdigit()])\n",
    "        regex_query = re.compile(candidate_name.replace(\" \", \".{0,1}\"), re.IGNORECASE)\n",
    "        metrics[\"candidates\"][_id_str][\"name_mentions\"] = api_db.col_tweets.count_documents({\"created_at\": get_filter_by_day(day), \"full_text\": regex_query})\n",
    "        # count mentions\n",
    "        metrics[\"candidates\"][_id_str][\"mentions\"] = api_db.col_tweets.count_documents({\"created_at\": get_filter_by_day(day), \"user_mentions\": _id})\n",
    "    # fixing fields that should not be updated historically\n",
    "    current = task.find_day(day)\n",
    "    if current:\n",
    "        for user, _id in candidates:\n",
    "            if _id <= 0: continue # ignore marcelo\n",
    "            _id_str = str(_id)\n",
    "            metrics[\"candidates\"][_id_str][\"followers_count\"] = current[\"data\"][\"candidates\"][_id_str][\"followers_count\"]\n",
    "    task.insert(day, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# task 5 - log creation dates weeks (users)\n",
    "from datetime import datetime\n",
    "# from collections import defaultdict\n",
    "def measure_creation_dates(day):\n",
    "    task = Task(api_db.db, \"measure creation dates\", only_one=True)\n",
    "\n",
    "    metrics = []\n",
    "    entries = api_db.col_users.aggregate([\n",
    "        { \"$group\" : {\n",
    "            \"_id\": {\n",
    "                \"year\" : { \"$year\" : \"$created_at\" },        \n",
    "                \"month\" : { \"$month\" : \"$created_at\" }\n",
    "                # , day : { $dayOfMonth : \"$created_at\" },\n",
    "            },\n",
    "            \"count\": { \"$sum\": 1 }\n",
    "        }}\n",
    "    ])\n",
    "    for x in entries:\n",
    "        metrics.append({\n",
    "            \"year\": x[\"_id\"][\"year\"],\n",
    "            \"month\": x[\"_id\"][\"month\"],\n",
    "            \"count\": x[\"count\"]\n",
    "        })\n",
    "    task.insert(day, metrics)\n",
    "measure_creation_dates(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(set1, set2):\n",
    "    if len(set1 | set2) == 0: return 0\n",
    "    return len(set1 & set2) / len(set1 | set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_of_1_follow_2(set1, set2):\n",
    "    if len(set1) == 0: return 0\n",
    "    return len(set1 & set2) / len(set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# task 6 - measure followers polarization\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "def measure_polarization(day):\n",
    "    task = Task(api_db.db, \"measure followers polarization\", only_one=True)\n",
    "\n",
    "    # get all followers\n",
    "    followers = defaultdict(set)\n",
    "    for cname, _id in candidates:\n",
    "        if _id <= 0: continue # ignore marcelo\n",
    "        for follower_ids in paged_followers(_id):\n",
    "            followers[_id].update(follower_ids)\n",
    "    # debug #followers\n",
    "    for k, v in followers.items(): print(\"%s has %s followers\" % (k, len(v)))\n",
    "    \n",
    "    polarization = []\n",
    "    for i, (cname, _id) in enumerate(candidates): # row\n",
    "        row = []\n",
    "        for j, (cname2, _id2) in enumerate(candidates): # col\n",
    "            if j<=i: row.append(0)\n",
    "            else: row.append(float(\"%.5f\" % jaccard_index(followers[_id], followers[_id2])))\n",
    "        polarization.append(row)\n",
    "\n",
    "    ratios = []\n",
    "    for i, (cname, _id) in enumerate(candidates): # row\n",
    "        row = []\n",
    "        for j, (cname2, _id2) in enumerate(candidates): # col\n",
    "            if j==i: row.append(0)\n",
    "            else: row.append(float(\"%.5f\" % how_many_of_1_follow_2(followers[_id], followers[_id2])))\n",
    "        ratios.append(row)\n",
    "\n",
    "    # debug polarization\n",
    "    print(\" \"*30, \" \".join([c[0] for c in candidates]))\n",
    "    [print(\"%30s\" % candidates[i][0], [\"%.4f\" % x for x in p]) for i, p in enumerate(polarization)]\n",
    "\n",
    "    task.insert(day, {\"candidates\": candidates, \"polarization\": polarization, \"ratios\": ratios})\n",
    "\n",
    "measure_polarization(datetime.now())"
   ]
  },
  {
   "source": [
    "# Main function that calls declared tasks\n",
    "Each task must be manually registered"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_caller(day):\n",
    "    print(\"\")\n",
    "    day_diff = (datetime.now(day.tzinfo) - day).days\n",
    "    recalculate = day_diff <= 10\n",
    "    print(\"Recalculating: %s\" % recalculate)\n",
    "    with DoneMessage(\"   count_tweets_by_type\"):count_tweets_by_type(day, recalculate)\n",
    "    with DoneMessage(\"   measure_fakenews\"):measure_fakenews(day, recalculate)\n",
    "    with DoneMessage(\"   measure_suspensions\"):measure_suspensions(day, recalculate)\n",
    "    with DoneMessage(\"   measure_candidates\"):measure_candidates(day, recalculate)\n",
    "    with DoneMessage(\"   measure_hatespeech\"):measure_hatespeech(day, recalculate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "day = misc.CONFIG[\"collection\"][\"oldest_tweet\"]\n",
    "# process every day from start to prev-yesterday (today only when whole day has gone by)\n",
    "while day.date() + timedelta(days=1) < datetime.now(day.tzinfo).date():\n",
    "    day+=timedelta(days=1)\n",
    "    with DoneMessage(\"Processing day %s\" % day):\n",
    "        main_caller(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}