{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Tweet Processing\n",
    "Iterate tweets for a given day and perform some calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "using 105 seed accounts (20 from news sources) and 0 hashtags\nDatabase stats: \n{'avgObjSize': 102.54450983689254,\n 'collections': 3,\n 'dataSize': 6098322.0,\n 'db': 'electionswatch',\n 'fsTotalSize': 510770802688.0,\n 'fsUsedSize': 444997160960.0,\n 'indexSize': 1077248.0,\n 'indexes': 3,\n 'numExtents': 0,\n 'objects': 59470,\n 'ok': 1.0,\n 'scaleFactor': 1.0,\n 'storageSize': 3387392.0,\n 'views': 0}\nDB size (B): 6098322.0\nDB size (MB): 5.82\nDB size (GB): 0.01\nUsing API keys for app albertina_01\n\nDone initializing at 10:04PM on September 26, 2020.\n----------------------------------------\n"
    }
   ],
   "source": [
    "# required imports to access api_db, misc, misc.CONFIG, ...\n",
    "import sys\n",
    "sys.path = ['.', '..', '../..'] + sys.path\n",
    "from collection import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 align=\"center\">driver code</h1>\n",
    "\n",
    "1. Define tasks to execute daily\n",
    "2. Check if these have been executed for each day of the past month\n",
    "3. Execute the ones that have not yet been executed (this ensures that new ones will be retroactively updated)\n",
    "4. "
   ]
  },
  {
   "source": [
    "---\n",
    "Define tasks below - these should be replicated in the api (or maybe make it generably able to access any `task_%s` collection from any endpoint, assuming injection is not a concern atm)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1 - count tweets by type\n",
    "from collections import defaultdict\n",
    "def count_tweets_by_type(day):\n",
    "    task = Task(api_db.db, \"count by type\")\n",
    "    if task.exists_day(day): return # already processed\n",
    "    metrics = defaultdict(int, next(api_db.col_tweets.aggregate([\n",
    "        {\"$match\": {\"created_at\": get_filter_by_day(day)}}, \n",
    "        {\"$facet\": {\n",
    "            \"retweet\": [\n",
    "                {\"$match\": {\"retweeted_status\": {\"$exists\": True}}},\n",
    "                {\"$count\": \"retweet\"},\n",
    "            ],\n",
    "            \"quote\": [\n",
    "                {\"$match\": {\"quoted_status\": {\"$exists\": True}}},\n",
    "                {\"$count\": \"quote\"},\n",
    "            ],\n",
    "            \"reply\": [\n",
    "                {\"$match\": {\"in_reply_to_status_id\": {\"$exists\": True}}},\n",
    "                {\"$count\": \"reply\"},\n",
    "            ],\n",
    "            \"original\": [\n",
    "                {\"$match\": {\"original\": True}},\n",
    "                {\"$count\": \"original\"},\n",
    "            ],\n",
    "            \"total\": [\n",
    "                {\"$count\": \"total\"},\n",
    "            ]\n",
    "        }},\n",
    "        {\"$project\": {\n",
    "            \"retweet\": {\"$arrayElemAt\": [\"$retweet.retweet\", 0]},\n",
    "            \"quote\": {\"$arrayElemAt\": [\"$quote.quote\", 0]},\n",
    "            \"reply\": {\"$arrayElemAt\": [\"$reply.reply\", 0]},\n",
    "            \"original\": {\"$arrayElemAt\": [\"$original.original\", 0]},\n",
    "            \"total\": {\"$arrayElemAt\": [\"$total.total\", 0]}\n",
    "        }}\n",
    "    ])))\n",
    "    # force defaultdict to create 0\n",
    "    [metrics[x] for x in [\"retweet\", \"quote\", \"reply\", \"original\", \"total\"]]\n",
    "    task.insert(day, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2 - measure fake news\n",
    "from collections import defaultdict, Counter\n",
    "def measure_fakenews(day):\n",
    "    task = Task(api_db.db, \"measure fakenews\")\n",
    "    if task.exists_day(day): return # already processed\n",
    "\n",
    "    # helper function\n",
    "    from urllib.parse import urlparse\n",
    "    def netloc(url): return urlparse(url.strip()).netloc.replace(\"www.\", \"\")\n",
    "\n",
    "    def normalize_name(name): return name.replace(\".\", \"-\")\n",
    "\n",
    "    # get fakenews sites\n",
    "    with open(\"fakenews.txt\") as inf: fakenews_sites = set(map(lambda s: s.strip(), inf.readlines()))\n",
    "    # search query\n",
    "    tweets = api_db.col_tweets.find({\n",
    "        \"urls\":{\"$exists\": True},\n",
    "        \"created_at\": get_filter_by_day(day)\n",
    "        }, {\"urls\": True, \"user\": True})\n",
    "    # collect\n",
    "    metrics = {\"total\":0, \"sites\": {}}\n",
    "    for fake in fakenews_sites: metrics[\"sites\"][normalize_name(fake)]=0\n",
    "    for t in tweets:\n",
    "        for url in t[\"urls\"]:\n",
    "            loc = netloc(url[\"expanded_url\"])\n",
    "            if loc == \"facebook.com\":\n",
    "                for fake in fakenews_sites:\n",
    "                    if fake in url[\"expanded_url\"]:\n",
    "                        metrics[\"sites\"][normalize_name(fake)]+=1\n",
    "                        break\n",
    "            elif loc in fakenews_sites:\n",
    "                metrics[\"sites\"][normalize_name(loc)]+=1\n",
    "    metrics[\"total\"] = sum(v for k, v in metrics[\"sites\"].items())\n",
    "    task.insert(day, metrics)"
   ]
  },
  {
   "source": [
    "# Main function that calls declared tasks\n",
    "Each task must be manually registered"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_caller(day):\n",
    "    print(\"\")\n",
    "    with DoneMessage(\"   count_tweets_by_type\"):count_tweets_by_type(day)\n",
    "    with DoneMessage(\"   measure_fakenews\"):measure_fakenews(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Processing day 2020-09-02 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.003s.\n   measure_fakenews...Done in 0.030s.\nDone in 0.038s.\nProcessing day 2020-09-03 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.018s.\nDone in 0.024s.\nProcessing day 2020-09-04 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.022s.\nDone in 0.027s.\nProcessing day 2020-09-05 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.003s.\n   measure_fakenews...Done in 0.017s.\nDone in 0.023s.\nProcessing day 2020-09-06 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.021s.\nDone in 0.025s.\nProcessing day 2020-09-07 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.015s.\nDone in 0.021s.\nProcessing day 2020-09-08 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.016s.\nDone in 0.021s.\nProcessing day 2020-09-09 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.001s.\n   measure_fakenews...Done in 0.023s.\nDone in 0.028s.\nProcessing day 2020-09-10 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.019s.\nDone in 0.025s.\nProcessing day 2020-09-11 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.018s.\nDone in 0.023s.\nProcessing day 2020-09-12 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.015s.\nDone in 0.019s.\nProcessing day 2020-09-13 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.015s.\nDone in 0.020s.\nProcessing day 2020-09-14 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.019s.\nDone in 0.024s.\nProcessing day 2020-09-15 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.017s.\nDone in 0.022s.\nProcessing day 2020-09-16 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.021s.\nDone in 0.027s.\nProcessing day 2020-09-17 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.001s.\n   measure_fakenews...Done in 0.019s.\nDone in 0.025s.\nProcessing day 2020-09-18 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.003s.\n   measure_fakenews...Done in 0.019s.\nDone in 0.023s.\nProcessing day 2020-09-19 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.017s.\nDone in 0.020s.\nProcessing day 2020-09-20 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.016s.\nDone in 0.022s.\nProcessing day 2020-09-21 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.021s.\nDone in 0.026s.\nProcessing day 2020-09-22 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.026s.\nDone in 0.033s.\nProcessing day 2020-09-23 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.028s.\nDone in 0.034s.\nProcessing day 2020-09-24 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.020s.\nDone in 0.028s.\nProcessing day 2020-09-25 00:00:00+00:00...\n   count_tweets_by_type...Done in 0.002s.\n   measure_fakenews...Done in 0.018s.\nDone in 0.023s.\n"
    }
   ],
   "source": [
    "day = misc.CONFIG[\"collection\"][\"oldest_tweet\"]\n",
    "# process every day from start to yesterday (today only when whole day has gone by)\n",
    "while day.date() + timedelta(days=1) < datetime.now(day.tzinfo).date():\n",
    "    day+=timedelta(days=1)\n",
    "    with DoneMessage(\"Processing day %s\" % day):\n",
    "        main_caller(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(get_account_details(20509689))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from datetime import timezone\n",
    "# find_params = find_exclude_invalid({\n",
    "#     \"depth\": 0\n",
    "# })\n",
    "# oldest_t = misc.CONFIG[\"collection\"][\"oldest_tweet\"]\n",
    "# # users = api_db.col_users.find(find_params, no_cursor_timeout=True)\n",
    "# users = [{\"_id\": 8665852}]\n",
    "# for u in users:\n",
    "#     print(\"getting tweets for: %s...\" % u[\"_id\"], end=\"\", flush=True)\n",
    "#     tweets = get_tweets(u, api_db.api.GetUserTimeline, \"since_id\",  datetime(2020, 7, 18, tzinfo=timezone.utc), {\"trim_user\":True})\n",
    "#     # insert_tweets(tweets)\n",
    "#     # update_most_common_language(u, tweets) # removed because not useful here\n",
    "#     print(\"got %d new tweets, done.\" % len(tweets))\n",
    "#     if len(tweets) > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # [print(str(t) + \"\\n\") for t in tweets[-10:-1]]\n",
    "# for t in tweets[0:10000]:\n",
    "#     if \"in_reply_to_user_id\" in t:\n",
    "#         print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc.CONFIG[\"collection\"][\"oldest_tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# for tweet in api_db.col_tweets.find({\"created_at\": {\"$gte\": _from, \"$lt\": _to}}, no_cursor_timeout=True):\n",
    "#     print(tweet)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}